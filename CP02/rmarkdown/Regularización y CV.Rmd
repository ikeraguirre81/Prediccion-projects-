---
title: "Regularización y CV con salarios de la NBA"
author: "Iker Aguirre Otaegui"
date: "07/11/2020"
output: html_document
---

### Objetivo del trabajo.

El objetivo de este trabajo es usar, entre otras, distintas métricas sobre el rendimiento de jugadores de la NBA con las que elaborar un modelo para predecir su posible salario. Se utilizarán las técnicas de cross validation y regularización para seleccionar el mejor modelo desde un punto de vista predictivo.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Carga de librerías.

```{r}
library(here) 
library(tidyverse)
library(janitor) 
library(skimr) 
library(magrittr) 
library(corrplot) 
library(ggcorrplot)  
library(PerformanceAnalytics) 
library(leaps) 
library(rsample) 
library(glmnet)   
library(dplyr)

```

## 2. Carga del dataset.

```{r}
nba_raw <- read.csv("nba.csv")
colnames(nba_raw)
```

## 3. Exploración de datos raw.

``` {r}
str(nba_raw)
```

```{r}
head(nba_raw)
```

```{r}
skim(nba_raw)
```

## 4. Limpieza de los datos.

Habiendo visto la composición de los datos en el dataset, realizo varias modificaciones que considero adecuadas para posteriores análisis. Entre ellos:

1. Omisión de valores NA

2. Rescribir el nombre variables a un formato adecuado

3. Elimino las variables "Player" y "Tm".

4. Modifico la variable "Country". Puesto que lo que realmente me interesa es si el jugador es estadounidense o internacional, le doy valores 1 a todas las observaciones que correspondan a jugadores americanos, y 0 al resto.

```{r}
nba <- drop_na(nba_raw)
nba %<>% clean_names()
```

```{r}
nba$player = NULL
nba$tm = NULL
```

```{r}
nba$nba_country[nba$nba_country != "USA"] <- 0
nba$nba_country[nba$nba_country == "USA"] <- 1 
```

```{r}
str(nba)
```

```{r}
head(nba)
```

```{r fig.height = 20, fig.width = 4, fig.align = "center"}
nba %>% 
  select_at(vars(-c(nba_country))) %>%  
  tidyr::gather("id", "value", 2:25) %>% 
  ggplot(., aes(y = salary, x = value)) +
  geom_point() +
  geom_smooth(method = "lm", se=FALSE, color = "black") + 
  facet_wrap(~id,ncol = 2,scales = "free_x")
```

## 5. Log.

Pasamos la variable "salary" a logaritmo.

```{r}
log_nba <- nba %>% 
  mutate(salary=log(salary))
```

## 6. Training and test sets.

Creamos dos subsets de la muestra: Uno de entrenamiento (80%) y otro de test (20%).

```{r}
set.seed(813)
train <- sample(nrow(log_nba), 0.8*nrow(log_nba), replace = FALSE )
nba_train <- log_nba[train,]
nba_test <- log_nba[-train,]
dim(nba_train)
dim(nba_test)
```

```{r}
nba_train_x <- model.matrix(salary ~ ., nba_train)[, -1]
nba_train_y <- log(nba_train$salary)

nba_test_x <- model.matrix(salary ~ ., nba_test)[, -1]
nba_test_y <- log(nba_test$salary)
```

## 7. Elastic Net.

Representamos la regularizaciónes Lasso y de Cresta, además de otras de fuerza más intermedia (alpha = 0.25 y 0.75).

```{r}
Elastic_net <- function(nba_train_x, nba_train_y){
  lasso <- glmnet(nba_train_x, nba_train_y, alpha = 1.0) 
  elastic1 <- glmnet(nba_train_x, nba_train_y, alpha = 0.25) 
  elastic2 <- glmnet(nba_train_x, nba_train_y, alpha = 0.75) 
  ridge <- glmnet(nba_train_x, nba_train_y, alpha = 0.0)
  par(mfrow = c(2, 2), mar = c(6, 4, 6, 2) + 0.1)
  plot(lasso, xvar = "lambda", main = "Lasso (Alpha = 1)\n\n\n")
  plot(elastic1, xvar = "lambda", main = "Elastic Net (Alpha = .25)\n\n\n")
  plot(elastic2, xvar = "lambda", main = "Elastic Net (Alpha = .75)\n\n\n")
  plot(ridge, xvar = "lambda", main = "Ridge (Alpha = 0)\n\n\n")
}
Elastic_net(nba_train_x, nba_train_y)


```

Hallamos las alphas mediante cross validation.

```{r}
fold_id <- sample(1:10, size = length(nba_train_y), replace=TRUE)

tuning_grid <- tibble::tibble(
  alpha = seq(0, 1, by = .1),
  mse_min = NA,
  mse_1se = NA,
  lambda_min = NA,
  lambda_1se = NA
)

for(i in seq_along(tuning_grid$alpha)) {
  fit <- cv.glmnet(nba_train_x, nba_train_y, alpha = tuning_grid$alpha[i], foldid = fold_id)
  tuning_grid$mse_min[i] <- fit$cvm[fit$lambda == fit$lambda.min]
  tuning_grid$mse_1se[i] <- fit$cvm[fit$lambda == fit$lambda.1se]
  tuning_grid$lambda_min[i] <- fit$lambda.min
  tuning_grid$lambda_1se[i] <- fit$lambda.1se
}
tuning_grid
```

Calculo el error de Lasso y Cresta.

```{r}
nba_lasso <- cv.glmnet(nba_train_x, nba_train_y, alpha = 1.0)
min(nba_lasso$cvm)
nba_ridge <- cv.glmnet(nba_train_x, nba_train_y, alpha = 0.0)
min(nba_ridge$cvm)
```

Al tener menor error, predecimos por Lasso con el test set.

```{r}
prediccion <- predict(nba_lasso, s = nba_lasso$lambda.min, nba_test_x)
mean((nba_test_y - prediccion)^2)
```
